# -*- coding: utf-8 -*-
"""streaming_lecture.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1WJJiCat3nF4shUtkuLAXt7-V_ulb-ufZ
"""

pip install pyspark

from pyspark.sql import SparkSession
spark = SparkSession.builder.getOrCreate()

part_of_data = spark.read.csv("/content/drive/MyDrive/2022/ปี 2/bigdata/paysim/part-00000-07197354-38af-4a89-a32d-02f319525a98-c000.csv", header=True, inferSchema=True)
part_of_data.show()

"""**5 steps of streaming query**:

1. define input source
2. transform data
3. define output sink and output mode
4. specify processing details
5. start the query
"""

#1.define input source
dataSchema = part_of_data.schema
#print(dataSchema)
streaming = spark.readStream.schema(dataSchema).csv("/content/drive/MyDrive/2022/ปี 2/bigdata/paysim_empty")

#2. transform data
import pyspark.sql.functions as F
dest_count = streaming.groupBy("nameDest").count().orderBy(F.desc("count"))

#3. define output sink and output mode -----> how to output ..file

writer = (dest_count.writeStream
                             .queryName("dest_counts")
                             .format("memory")
                             .outputMode("complete"))

from os import write
#4. specify processing details -----> how to trigger

writer2 = writer.trigger(processingTime="1 second")

#5. start the query
streamingQuery = writer2.start()

#use the stream

df = spark.sql("SELECT * FROM dest_counts")

df.show()